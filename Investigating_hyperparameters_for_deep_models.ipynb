{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPtPWg0kY6-s"
      },
      "source": [
        "#Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lbwa9IZVZAPO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC6Lqh7iZbpO",
        "outputId": "34d677b4-0390-42ed-df69-57f285ecec8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                            message\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   label    5572 non-null   object\n",
            " 1   message  5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# بارگذاری داده‌ها\n",
        "url = \"https://raw.githubusercontent.com/justmarkham/DAT8/master/data/sms.tsv\"\n",
        "data = pd.read_csv(url, sep='\\t', header=None, names=['label', 'message'])\n",
        "\n",
        "# نمایش چند سطر از داده‌ها برای بررسی\n",
        "print(data.head())\n",
        "\n",
        "# نمایش اطلاعات کلی از داده‌ها\n",
        "print(data.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7-pBpMbd0np",
        "outputId": "08a9085a-cc6d-42d1-c12f-6e3082179a2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label      0\n",
            "message    0\n",
            "dtype: int64\n",
            "Number of samples after removing NaN values: 5572\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# بررسی وجود مقادیر NaN\n",
        "print(data.isna().sum())\n",
        "\n",
        "# حذف سطرهایی که برچسب یا پیام آنها NaN است\n",
        "data.dropna(subset=['label', 'message'], inplace=True)\n",
        "\n",
        "# بررسی تعداد داده‌ها پس از حذف NaN\n",
        "print(f\"Number of samples after removing NaN values: {len(data)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvAuzQyfYU8T",
        "outputId": "75907b91-b70a-4db4-a0a4-6f73f7939bb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples after removing NaN values: 5572\n",
            "No NaN values found in y_test.\n",
            "35/35 [==============================] - 1s 17ms/step\n",
            "Hidden Layers: 0, Accuracy: 0.9883\n",
            "35/35 [==============================] - 1s 19ms/step\n",
            "Hidden Layers: 1, Accuracy: 0.9892\n",
            "35/35 [==============================] - 1s 19ms/step\n",
            "Hidden Layers: 2, Accuracy: 0.9883\n",
            "35/35 [==============================] - 1s 18ms/step\n",
            "Hidden Layers: 3, Accuracy: 0.9892\n",
            "35/35 [==============================] - 2s 28ms/step\n",
            "Hidden Layers: 4, Accuracy: 0.9892\n",
            "35/35 [==============================] - 1s 19ms/step\n",
            "Hidden Layers: 5, Accuracy: 0.9892\n",
            "Hidden Layers: 0, Accuracy: 0.9883\n",
            "Hidden Layers: 1, Accuracy: 0.9892\n",
            "Hidden Layers: 2, Accuracy: 0.9883\n",
            "Hidden Layers: 3, Accuracy: 0.9892\n",
            "Hidden Layers: 4, Accuracy: 0.9892\n",
            "Hidden Layers: 5, Accuracy: 0.9892\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "url = \"https://raw.githubusercontent.com/justmarkham/DAT8/master/data/sms.tsv\"\n",
        "data = pd.read_csv(url, sep='\\t', header=None, names=['label', 'message'])\n",
        "\n",
        "# تبدیل برچسب‌ها به اعداد (0 برای ham و 1 برای spam)\n",
        "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# حذف سطرهایی که برچسب یا پیام آنها NaN است\n",
        "data.dropna(subset=['label', 'message'], inplace=True)\n",
        "\n",
        "# بررسی تعداد داده‌ها پس از حذف NaN\n",
        "print(f\"Number of samples after removing NaN values: {len(data)}\")\n",
        "\n",
        "# تقسیم داده‌ها به ویژگی‌ها و برچسب‌ها\n",
        "X = data['message'].values\n",
        "y = data['label'].values\n",
        "\n",
        "# تبدیل متن‌ها به توالی‌های اعداد\n",
        "vocab_size = 10000\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "# پدینگ کردن توالی‌ها به طول ثابت\n",
        "maxlen = 100\n",
        "X = pad_sequences(X, maxlen=maxlen)\n",
        "\n",
        "# تقسیم داده‌ها به مجموعه آموزش و تست\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# بررسی وجود NaN در y_test\n",
        "if np.any(np.isnan(y_test)):\n",
        "    print(\"NaN values found in y_test.\")\n",
        "else:\n",
        "    print(\"No NaN values found in y_test.\")\n",
        "\n",
        "def create_model(hidden_layers, hidden_size, activation='relu'):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=maxlen))\n",
        "    model.add(LSTM(64, return_sequences=False))  # return_sequences=False برای آخرین لایه LSTM\n",
        "    for _ in range(hidden_layers):\n",
        "        model.add(Dense(hidden_size, activation=activation))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# ارزیابی تاثیر تعداد لایه‌های مخفی\n",
        "hidden_layers_options = [0, 1, 2, 3, 4, 5]\n",
        "results = []\n",
        "\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    model = create_model(hidden_layers, hidden_size=64)\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=0)\n",
        "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append((hidden_layers, accuracy))\n",
        "    print(f'Hidden Layers: {hidden_layers}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# نمایش نتایج\n",
        "for hidden_layers, accuracy in results:\n",
        "    print(f'Hidden Layers: {hidden_layers}, Accuracy: {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "url = \"https://raw.githubusercontent.com/justmarkham/DAT8/master/data/sms.tsv\"\n",
        "data = pd.read_csv(url, sep='\\t', header=None, names=['label', 'message'])\n",
        "\n",
        "# تبدیل برچسب‌ها به اعداد (0 برای ham و 1 برای spam)\n",
        "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# حذف سطرهایی که برچسب یا پیام آنها NaN است\n",
        "data.dropna(subset=['label', 'message'], inplace=True)\n",
        "\n",
        "# بررسی تعداد داده‌ها پس از حذف NaN\n",
        "print(f\"Number of samples after removing NaN values: {len(data)}\")\n",
        "\n",
        "# تقسیم داده‌ها به ویژگی‌ها و برچسب‌ها\n",
        "X = data['message'].values\n",
        "y = data['label'].values\n",
        "\n",
        "# تبدیل متن‌ها به توالی‌های اعداد\n",
        "vocab_sizes = [8000, 5000, 2000]\n",
        "results = []\n",
        "\n",
        "for vocab_size in vocab_sizes:\n",
        "    tokenizer = Tokenizer(num_words=vocab_size)\n",
        "    tokenizer.fit_on_texts(X)\n",
        "    X_seq = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "    # پدینگ کردن توالی‌ها به طول ثابت\n",
        "    maxlen = 100\n",
        "    X_pad = pad_sequences(X_seq, maxlen=maxlen)\n",
        "\n",
        "    # تقسیم داده‌ها به مجموعه آموزش و تست\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    def create_model(hidden_layers, hidden_size, activation='relu'):\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=maxlen))\n",
        "        model.add(LSTM(64, return_sequences=False))  # return_sequences=False برای آخرین لایه LSTM\n",
        "        for _ in range(hidden_layers):\n",
        "            model.add(Dense(hidden_size, activation=activation))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    # ارزیابی تاثیر تعداد لایه‌های مخفی\n",
        "    hidden_layers = 2  # ثابت نگه داشتن تعداد لایه‌های مخفی\n",
        "    hidden_size = 64  # ثابت نگه داشتن اندازه لایه‌های مخفی\n",
        "    model = create_model(hidden_layers, hidden_size)\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=0)\n",
        "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append((vocab_size, accuracy))\n",
        "    print(f'Vocab Size: {vocab_size}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# نمایش نتایج\n",
        "for vocab_size, accuracy in results:\n",
        "    print(f'Vocab Size: {vocab_size}, Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBpb1ll_msk6",
        "outputId": "0c9dfaab-4475-4471-b9d6-aad4896fd99a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples after removing NaN values: 5572\n",
            "35/35 [==============================] - 1s 14ms/step\n",
            "Vocab Size: 8000, Accuracy: 0.9892\n",
            "35/35 [==============================] - 1s 15ms/step\n",
            "Vocab Size: 5000, Accuracy: 0.9874\n",
            "35/35 [==============================] - 1s 19ms/step\n",
            "Vocab Size: 2000, Accuracy: 0.9910\n",
            "Vocab Size: 8000, Accuracy: 0.9892\n",
            "Vocab Size: 5000, Accuracy: 0.9874\n",
            "Vocab Size: 2000, Accuracy: 0.9910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "url = \"https://raw.githubusercontent.com/justmarkham/DAT8/master/data/sms.tsv\"\n",
        "data = pd.read_csv(url, sep='\\t', header=None, names=['label', 'message'])\n",
        "\n",
        "# تبدیل برچسب‌ها به اعداد (0 برای ham و 1 برای spam)\n",
        "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# حذف سطرهایی که برچسب یا پیام آنها NaN است\n",
        "data.dropna(subset=['label', 'message'], inplace=True)\n",
        "\n",
        "# بررسی تعداد داده‌ها پس از حذف NaN\n",
        "print(f\"Number of samples after removing NaN values: {len(data)}\")\n",
        "\n",
        "# تقسیم داده‌ها به ویژگی‌ها و برچسب‌ها\n",
        "X = data['message'].values\n",
        "y = data['label'].values\n",
        "\n",
        "# تبدیل متن‌ها به توالی‌های اعداد\n",
        "vocab_size = 10000\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_seq = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "# پدینگ کردن توالی‌ها به طول ثابت\n",
        "maxlen = 100\n",
        "X_pad = pad_sequences(X_seq, maxlen=maxlen)\n",
        "\n",
        "# تقسیم داده‌ها به مجموعه آموزش و تست\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def create_model(hidden_layers, hidden_size, activation='relu'):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=maxlen))\n",
        "    model.add(LSTM(64, return_sequences=False))  # return_sequences=False برای آخرین لایه LSTM\n",
        "    for _ in range(hidden_layers):\n",
        "        model.add(Dense(hidden_size, activation=activation))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# ارزیابی تاثیر توابع فعال‌سازی مختلف\n",
        "activation_functions = ['relu', 'sigmoid', 'linear']\n",
        "results = []\n",
        "\n",
        "for activation in activation_functions:\n",
        "    hidden_layers = 2  # ثابت نگه داشتن تعداد لایه‌های مخفی\n",
        "    hidden_size = 64  # ثابت نگه داشتن اندازه لایه‌های مخفی\n",
        "    model = create_model(hidden_layers, hidden_size, activation=activation)\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=0)\n",
        "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append((activation, accuracy))\n",
        "    print(f'Activation Function: {activation}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# نمایش نتایج\n",
        "for activation, accuracy in results:\n",
        "    print(f'Activation Function: {activation}, Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4PuphFinMl_",
        "outputId": "0ef4d3cb-d221-406c-bcd2-ff1ba4fe8de0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples after removing NaN values: 5572\n",
            "35/35 [==============================] - 1s 16ms/step\n",
            "Activation Function: relu, Accuracy: 0.9910\n",
            "35/35 [==============================] - 1s 14ms/step\n",
            "Activation Function: sigmoid, Accuracy: 0.9901\n",
            "35/35 [==============================] - 1s 15ms/step\n",
            "Activation Function: linear, Accuracy: 0.9883\n",
            "Activation Function: relu, Accuracy: 0.9910\n",
            "Activation Function: sigmoid, Accuracy: 0.9901\n",
            "Activation Function: linear, Accuracy: 0.9883\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}